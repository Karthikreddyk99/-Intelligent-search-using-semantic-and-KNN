{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) - Initial Data Scraping and Observations\n",
    "\n",
    "In this notebook, Firstly data scraping process and the insights gained from the dataset. This initial step is crucial to understand the dataset, its metadata, and the relationships between data and its features.\n",
    "\n",
    "**Data Overview:**\n",
    "\n",
    "To get an overview of the dataset, I used various Python libraries like `pyspark` `pandas` to load and explore the data. \n",
    "\n",
    "Exploratory Data Analysis (EDA) - Initial Data Scraping and Observations\n",
    "\n",
    "**Data Overview:**\n",
    "\n",
    "To get an overview of the dataset, I used various Python libraries like pyspark and pandas to load and explore the data.\n",
    "\n",
    "**Data Preprocessing:**\n",
    "\n",
    "Data preprocessing is a crucial step to ensure that the data is in a usable format. This involves handling missing values, encoding categorical variables, and scaling or normalizing features as needed. I performed the following preprocessing steps:\n",
    "\n",
    "1. Data Loading: I used PySpark and Pandas to load the dataset.\n",
    "2. Handling Missing Values: Checked for missing values and decided whether to impute or remove them.\n",
    "3. Encoding Categorical Variables: Encoded categorical variables when necessary.\n",
    "4. Feature Scaling/Normalization: Scaled or normalized features as required.\n",
    "\n",
    "**Initial Observations:**\n",
    "\n",
    "After loading and preprocessing the data, I conducted an initial analysis to gain insights into the dataset:\n",
    "\n",
    "- Data Size: The datasets contains different number of rows and columns.\n",
    "- Feature Types: I observed that the dataset includes features of different types, such as categorical, and text.\n",
    "- Missing Values: I checked for missing values in the dataset. If any were found, I determined whether to impute missing data or remove instances with missing values.\n",
    "- Descriptive Statistics: I calculated basic summary statistics, including mean, median, standard deviation, and quartiles for count of features.\n",
    "\n",
    "**Further Steps:**\n",
    "\n",
    "Based on these initial observations, I planned to establish relationships of the Features Product, Retailer, Brand with OFFER, which may include feature engineering and deeper exploratory analysis.\n",
    "\n",
    "By conducting this initial data scraping and observation, I have laid the foundation for a more comprehensive analysis of the dataset. Understanding the dataset and its metadata is essential for making informed decisions throughout the data analysis and modeling process. Next, I will proceed with more in-depth exploratory analysis and feature engineering to extract valuable insights from the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\karth\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: pyspark[sql] in c:\\users\\karth\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pyspark[sql]) (0.10.9.7)\n",
      "Requirement already satisfied: pandas>=1.0.5; extra == \"sql\" in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pyspark[sql]) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.15; extra == \"sql\" in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pyspark[sql]) (1.19.2)\n",
      "Requirement already satisfied: pyarrow>=1.0.0; extra == \"sql\" in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pyspark[sql]) (12.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pandas>=1.0.5; extra == \"sql\"->pyspark[sql]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pandas>=1.0.5; extra == \"sql\"->pyspark[sql]) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.0.5; extra == \"sql\"->pyspark[sql]) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\karth\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\karth\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six in c:\\users\\karth\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\karth\\anaconda3\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install pyspark[sql]\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\anaconda3\\lib\\site-packages\\pyspark\\context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Fetch\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[BRAND: string, BRAND_BELONGS_TO_CATEGORY: string, RECEIPTS: int]\n",
      "+-------+-----------------+-------------------------+\n",
      "|summary|            BRAND|BRAND_BELONGS_TO_CATEGORY|\n",
      "+-------+-----------------+-------------------------+\n",
      "|  count|             9906|                     9906|\n",
      "|   mean|          1000.45|                     null|\n",
      "| stddev|841.6671097792823|                     null|\n",
      "|    min|                1|       Adult Incontinence|\n",
      "|    max|    breath savers|                   Yogurt|\n",
      "+-------+-----------------+-------------------------+\n",
      "\n",
      "+-----+-------------------------+\n",
      "|BRAND|BRAND_BELONGS_TO_CATEGORY|\n",
      "+-----+-------------------------+\n",
      "|   NA|                     Beer|\n",
      "+-----+-------------------------+\n",
      "\n",
      "+-----+-------------------------+\n",
      "|BRAND|BRAND_BELONGS_TO_CATEGORY|\n",
      "+-----+-------------------------+\n",
      "+-----+-------------------------+\n",
      "\n",
      "+------------------+-------------------------+\n",
      "|             BRAND|BRAND_BELONGS_TO_CATEGORY|\n",
      "+------------------+-------------------------+\n",
      "|  CASEYS GEN STORE|         Tobacco Products|\n",
      "|  CASEYS GEN STORE|                   Mature|\n",
      "|            EQUATE|             Hair Removal|\n",
      "|         PALMOLIVE|              Bath & Body|\n",
      "|              DAWN|              Bath & Body|\n",
      "|          BARBASOL|             Hair Removal|\n",
      "|            KROGER|                   Bakery|\n",
      "|        SKINTIMATE|             Hair Removal|\n",
      "|     DAWN PLATINUM|              Bath & Body|\n",
      "|KIRKLAND SIGNATURE|              Bath & Body|\n",
      "|          RED BULL|     Carbonated Soft D...|\n",
      "|         COCA-COLA|     Carbonated Soft D...|\n",
      "|              AJAX|              Bath & Body|\n",
      "|            EQUATE|              Bath & Body|\n",
      "|         DR PEPPER|     Carbonated Soft D...|\n",
      "|        BODYCOLOGY|          Body Fragrances|\n",
      "|           KINDERS|             Dips & Salsa|\n",
      "|    BODY FANTASIES|          Body Fragrances|\n",
      "|      MOUNTAIN DEW|     Carbonated Soft D...|\n",
      "|           MONSTER|     Carbonated Soft D...|\n",
      "+------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|               BRAND|\n",
      "+--------------------+\n",
      "|             TOTINOS|\n",
      "|     VEUVE DU VERNAY|\n",
      "|            Goldfish|\n",
      "|        GOOSE ISLAND|\n",
      "|            SABRITAS|\n",
      "|          HEAVY SEAS|\n",
      "|      YARDLEY LONDON|\n",
      "|              DEPEND|\n",
      "|         WILD TURKEY|\n",
      "|              DUCLAW|\n",
      "|             SUNBELT|\n",
      "|THE GRAND CANYON ...|\n",
      "|             PENROSE|\n",
      "|               GRAFT|\n",
      "|           ELLINGTON|\n",
      "|          LA FAMILIA|\n",
      "|           LEMONHEAD|\n",
      "|              BAYERN|\n",
      "|NINKASI BREWING C...|\n",
      "|FOX RIVER BREWING CO|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|               BRAND|count|\n",
      "+--------------------+-----+\n",
      "|             TOTINOS|    1|\n",
      "|     VEUVE DU VERNAY|    1|\n",
      "|            Goldfish|    1|\n",
      "|        GOOSE ISLAND|    1|\n",
      "|            SABRITAS|    3|\n",
      "|          HEAVY SEAS|    1|\n",
      "|      YARDLEY LONDON|    1|\n",
      "|              DEPEND|    1|\n",
      "|         WILD TURKEY|    1|\n",
      "|              DUCLAW|    1|\n",
      "|             SUNBELT|    2|\n",
      "|THE GRAND CANYON ...|    1|\n",
      "|             PENROSE|    1|\n",
      "|               GRAFT|    1|\n",
      "|           ELLINGTON|    1|\n",
      "|          LA FAMILIA|    1|\n",
      "|           LEMONHEAD|    1|\n",
      "|              BAYERN|    1|\n",
      "|NINKASI BREWING C...|    1|\n",
      "|FOX RIVER BREWING CO|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------------+\n",
      "|BRAND_BELONGS_TO_CATEGORY|\n",
      "+-------------------------+\n",
      "|                    Water|\n",
      "|                  Spirits|\n",
      "|          Frozen Desserts|\n",
      "|        Frozen Vegetables|\n",
      "|                Nail Care|\n",
      "|                   Bakery|\n",
      "|                      Tea|\n",
      "|                Trail Mix|\n",
      "|                   Yogurt|\n",
      "|            Puffed Snacks|\n",
      "|                 Crackers|\n",
      "|         Frozen Breakfast|\n",
      "|         Cooking & Baking|\n",
      "|                     Milk|\n",
      "|        Pudding & Gelatin|\n",
      "|      Packaged Vegetables|\n",
      "|             Baby Bathing|\n",
      "|                      Ice|\n",
      "|                 Pretzels|\n",
      "|              Frozen Beef|\n",
      "+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------------+-----+\n",
      "|BRAND_BELONGS_TO_CATEGORY|count|\n",
      "+-------------------------+-----+\n",
      "|                    Water|   77|\n",
      "|                  Spirits| 1850|\n",
      "|          Frozen Desserts|   42|\n",
      "|        Frozen Vegetables|   12|\n",
      "|                Nail Care|    5|\n",
      "|                   Bakery|   61|\n",
      "|                      Tea|   42|\n",
      "|                Trail Mix|    4|\n",
      "|                   Yogurt|   35|\n",
      "|            Puffed Snacks|   30|\n",
      "|                 Crackers|   60|\n",
      "|         Frozen Breakfast|   20|\n",
      "|         Cooking & Baking|  223|\n",
      "|                     Milk|   23|\n",
      "|        Pudding & Gelatin|    6|\n",
      "|      Packaged Vegetables|   24|\n",
      "|             Baby Bathing|   41|\n",
      "|                      Ice|    2|\n",
      "|                 Pretzels|   15|\n",
      "|              Frozen Beef|    3|\n",
      "+-------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = spark.read.csv(\"C:/Users/karth/Desktop/Fetch_project/Data/brand_category.csv\", header=True, inferSchema=True)\n",
    "\n",
    "print(data_df)\n",
    "\n",
    "data_df.fillna(\"NA\")\n",
    "\n",
    "data = data_df.drop(\"RECEIPTS\")\n",
    "\n",
    "data.describe().show()\n",
    "\n",
    "data.filter(data[\"BRAND\"] == \"NA\").show()\n",
    "\n",
    "data.filter(data[\"BRAND_BELONGS_TO_CATEGORY\"] == \"NA\").show()\n",
    "\n",
    "data.show()\n",
    "\n",
    "unique_brands = data.select(\"BRAND\").distinct()\n",
    "unique_brands.show()\n",
    "\n",
    "category_count = data.groupBy(\"BRAND\").count()\n",
    "category_count.show()\n",
    "\n",
    "unique_categories = data.select(\"BRAND_BELONGS_TO_CATEGORY\").distinct()\n",
    "unique_categories.show()\n",
    "\n",
    "category_counts = data.groupBy(\"BRAND_BELONGS_TO_CATEGORY\").count()\n",
    "category_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+--------------------+\n",
      "|CATEGORY_ID|PRODUCT_CATEGORY|IS_CHILD_CATEGORY_TO|\n",
      "+-----------+----------------+--------------------+\n",
      "+-----------+----------------+--------------------+\n",
      "\n",
      "+-----------+----------------+--------------------+\n",
      "|CATEGORY_ID|PRODUCT_CATEGORY|IS_CHILD_CATEGORY_TO|\n",
      "+-----------+----------------+--------------------+\n",
      "+-----------+----------------+--------------------+\n",
      "\n",
      "+-----------+----------------+--------------------+\n",
      "|CATEGORY_ID|PRODUCT_CATEGORY|IS_CHILD_CATEGORY_TO|\n",
      "+-----------+----------------+--------------------+\n",
      "+-----------+----------------+--------------------+\n",
      "\n",
      "+-------+--------------------+------------------+--------------------+\n",
      "|summary|         CATEGORY_ID|  PRODUCT_CATEGORY|IS_CHILD_CATEGORY_TO|\n",
      "+-------+--------------------+------------------+--------------------+\n",
      "|  count|                 118|               118|                 118|\n",
      "|   mean|                null|              null|                null|\n",
      "| stddev|                null|              null|                null|\n",
      "|    min|01edb86e-b0b3-41c...|Adult Incontinence|             Alcohol|\n",
      "|    max|f81d7064-52da-4bd...|            Yogurt|Sports Drinks & E...|\n",
      "+-------+--------------------+------------------+--------------------+\n",
      "\n",
      "+-------+------------------+--------------------+\n",
      "|summary|  PRODUCT_CATEGORY|IS_CHILD_CATEGORY_TO|\n",
      "+-------+------------------+--------------------+\n",
      "|  count|               118|                 118|\n",
      "|   mean|              null|                null|\n",
      "| stddev|              null|                null|\n",
      "|    min|Adult Incontinence|             Alcohol|\n",
      "|    max|            Yogurt|Sports Drinks & E...|\n",
      "+-------+------------------+--------------------+\n",
      "\n",
      "+-------------------+\n",
      "|   PRODUCT_CATEGORY|\n",
      "+-------------------+\n",
      "|              Water|\n",
      "|            Spirits|\n",
      "|    Frozen Desserts|\n",
      "|  Frozen Vegetables|\n",
      "|          Nail Care|\n",
      "|             Bakery|\n",
      "|                Tea|\n",
      "|          Trail Mix|\n",
      "|             Yogurt|\n",
      "|      Puffed Snacks|\n",
      "|           Crackers|\n",
      "|   Frozen Breakfast|\n",
      "|   Cooking & Baking|\n",
      "|               Milk|\n",
      "|  Pudding & Gelatin|\n",
      "|Packaged Vegetables|\n",
      "|       Baby Bathing|\n",
      "|                Ice|\n",
      "|           Pretzels|\n",
      "|        Fresh Pasta|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-----+\n",
      "|   PRODUCT_CATEGORY|count|\n",
      "+-------------------+-----+\n",
      "|              Water|    1|\n",
      "|            Spirits|    1|\n",
      "|    Frozen Desserts|    1|\n",
      "|  Frozen Vegetables|    1|\n",
      "|          Nail Care|    1|\n",
      "|             Bakery|    1|\n",
      "|                Tea|    1|\n",
      "|          Trail Mix|    1|\n",
      "|             Yogurt|    1|\n",
      "|      Puffed Snacks|    1|\n",
      "|           Crackers|    1|\n",
      "|   Frozen Breakfast|    1|\n",
      "|   Cooking & Baking|    1|\n",
      "|               Milk|    1|\n",
      "|  Pudding & Gelatin|    1|\n",
      "|Packaged Vegetables|    1|\n",
      "|       Baby Bathing|    1|\n",
      "|                Ice|    1|\n",
      "|           Pretzels|    1|\n",
      "|        Fresh Pasta|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|IS_CHILD_CATEGORY_TO|\n",
      "+--------------------+\n",
      "|             Spirits|\n",
      "|         Frozen Meat|\n",
      "|       Puffed Snacks|\n",
      "|              Pantry|\n",
      "|   Health & Wellness|\n",
      "|       Home & Garden|\n",
      "|Sports Drinks & E...|\n",
      "|           Oral Care|\n",
      "|           Beverages|\n",
      "|               Dairy|\n",
      "|      Meat & Seafood|\n",
      "|              Mature|\n",
      "|               Candy|\n",
      "|             Alcohol|\n",
      "|              Frozen|\n",
      "|  Household Supplies|\n",
      "|         Pasta Sauce|\n",
      "|       Deli & Bakery|\n",
      "|     Pasta & Noodles|\n",
      "|Animals & Pet Sup...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|IS_CHILD_CATEGORY_TO|count|\n",
      "+--------------------+-----+\n",
      "|             Spirits|    2|\n",
      "|         Frozen Meat|    4|\n",
      "|       Puffed Snacks|    1|\n",
      "|              Pantry|   16|\n",
      "|   Health & Wellness|   13|\n",
      "|       Home & Garden|    1|\n",
      "|Sports Drinks & E...|    1|\n",
      "|           Oral Care|    1|\n",
      "|           Beverages|    9|\n",
      "|               Dairy|    9|\n",
      "|      Meat & Seafood|    1|\n",
      "|              Mature|    2|\n",
      "|               Candy|    1|\n",
      "|             Alcohol|    6|\n",
      "|              Frozen|   12|\n",
      "|  Household Supplies|    5|\n",
      "|         Pasta Sauce|    3|\n",
      "|       Deli & Bakery|    4|\n",
      "|     Pasta & Noodles|    2|\n",
      "|Animals & Pet Sup...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df1 = spark.read.csv(\"C:/Users/karth/Desktop/Fetch_project/Data/categories.csv\", header=True, inferSchema=True)\n",
    "\n",
    "data_df1.filter(data_df1['CATEGORY_ID'].isNull()).show()\n",
    "\n",
    "data_df1.filter(data_df1['PRODUCT_CATEGORY'].isNull()).show()\n",
    "\n",
    "data_df1.filter(data_df1['IS_CHILD_CATEGORY_TO'].isNull()).show()\n",
    "\n",
    "data_df1.describe().show()\n",
    "\n",
    "data1 = data_df1.drop(\"CATEGORY_ID\")\n",
    "\n",
    "data1.describe().show()\n",
    "\n",
    "unique_PRODUCT_CATEGORY = data1.select(\"PRODUCT_CATEGORY\").distinct()\n",
    "unique_PRODUCT_CATEGORY.show()\n",
    "\n",
    "PRODUCT_CATEGORY_count = data1.groupBy(\"PRODUCT_CATEGORY\").count()\n",
    "PRODUCT_CATEGORY_count.show()\n",
    "\n",
    "IS_CHILD_CATEGORY_TO_categories = data1.select(\"IS_CHILD_CATEGORY_TO\").distinct()\n",
    "IS_CHILD_CATEGORY_TO_categories.show()\n",
    "\n",
    "IS_CHILD_CATEGORY_TO_counts = data1.groupBy(\"IS_CHILD_CATEGORY_TO\").count()\n",
    "IS_CHILD_CATEGORY_TO_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----+\n",
      "|OFFER|RETAILER|BRAND|\n",
      "+-----+--------+-----+\n",
      "+-----+--------+-----+\n",
      "\n",
      "+--------------------+--------+--------------------+\n",
      "|               OFFER|RETAILER|               BRAND|\n",
      "+--------------------+--------+--------------------+\n",
      "|Beyond Meat® Plan...|    null|         BEYOND MEAT|\n",
      "|Good Humor Vienne...|    null|          GOOD HUMOR|\n",
      "|Emmy's Organics® ...|    null|        EMMYS POP UP|\n",
      "|Barilla® Pesto Sauce|    null|             BARILLA|\n",
      "|Any General Mills...|    null|                null|\n",
      "|Good Rewards Memb...|    null|ANNIES HOMEGROWN ...|\n",
      "|DOVE® Chocolate, ...|    null|      DOVE CHOCOLATE|\n",
      "|Hellmann's® OR Be...|    null|HELLMANNS BEST FOODS|\n",
      "|M&M'S®, select si...|    null|                M&MS|\n",
      "|GATORLYTE® OR GAT...|    null|            GATORADE|\n",
      "|Red Gold Tomato K...|    null|            RED GOLD|\n",
      "|Gillette Venus ® ...|    null|      GILLETTE VENUS|\n",
      "|Simply Spiked™ Le...|    null|       SIMPLY SPIKED|\n",
      "|Tru-Ray® Premium ...|    null|              TRURAY|\n",
      "|CESAR® Wet Dog Fo...|    null|               CESAR|\n",
      "| TWIX®, select sizes|    null|                TWIX|\n",
      "|M&M'S® chocolate ...|    null|                M&MS|\n",
      "|Hidden Valley® Ra...|    null| HIDDEN VALLEY RANCH|\n",
      "|Creativity Street...|    null|   CREATIVITY STREET|\n",
      "|Crunchmaster® Cra...|    null|        CRUNCHMASTER|\n",
      "+--------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------+-----+\n",
      "|               OFFER|RETAILER|BRAND|\n",
      "+--------------------+--------+-----+\n",
      "|Any General Mills...|    null| null|\n",
      "+--------------------+--------+-----+\n",
      "\n",
      "+--------------------+--------+--------------------+\n",
      "|               OFFER|RETAILER|               BRAND|\n",
      "+--------------------+--------+--------------------+\n",
      "|Beyond Meat® Plan...|      NA|         BEYOND MEAT|\n",
      "|Good Humor Vienne...|      NA|          GOOD HUMOR|\n",
      "|Emmy's Organics® ...|      NA|        EMMYS POP UP|\n",
      "|Barilla® Pesto Sauce|      NA|             BARILLA|\n",
      "|Any General Mills...|      NA|                  NA|\n",
      "|Good Rewards Memb...|      NA|ANNIES HOMEGROWN ...|\n",
      "|DOVE® Chocolate, ...|      NA|      DOVE CHOCOLATE|\n",
      "|Hellmann's® OR Be...|      NA|HELLMANNS BEST FOODS|\n",
      "|M&M'S®, select si...|      NA|                M&MS|\n",
      "|GATORLYTE® OR GAT...|      NA|            GATORADE|\n",
      "|Red Gold Tomato K...|      NA|            RED GOLD|\n",
      "|Gillette Venus ® ...|      NA|      GILLETTE VENUS|\n",
      "|Simply Spiked™ Le...|      NA|       SIMPLY SPIKED|\n",
      "|Tru-Ray® Premium ...|      NA|              TRURAY|\n",
      "|CESAR® Wet Dog Fo...|      NA|               CESAR|\n",
      "| TWIX®, select sizes|      NA|                TWIX|\n",
      "|M&M'S® chocolate ...|      NA|                M&MS|\n",
      "|Hidden Valley® Ra...|      NA| HIDDEN VALLEY RANCH|\n",
      "|Creativity Street...|      NA|   CREATIVITY STREET|\n",
      "|Crunchmaster® Cra...|      NA|        CRUNCHMASTER|\n",
      "+--------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------------------+--------+------+\n",
      "|summary|               OFFER|RETAILER| BRAND|\n",
      "+-------+--------------------+--------+------+\n",
      "|  count|                 385|     385|   385|\n",
      "|   mean|                null|    null|  null|\n",
      "| stddev|                null|    null|  null|\n",
      "|    min|12 Pack OR 2 Lite...|    ACME| 5 GUM|\n",
      "|    max|Wonderworks™ Keto...|  ZAXBYS|ZAXBYS|\n",
      "+-------+--------------------+--------+------+\n",
      "\n",
      "+--------------------+\n",
      "|               OFFER|\n",
      "+--------------------+\n",
      "| Spend $185 at Shaws|\n",
      "|Back to the Roots...|\n",
      "|SKITTLES®, select...|\n",
      "|Gorton's at selec...|\n",
      "|Spend $50 on a Fu...|\n",
      "|Jack Link's®, sel...|\n",
      "|Ben & Jerry's®, s...|\n",
      "|Wesson® Oil Products|\n",
      "|Spend $115 at Saf...|\n",
      "|Hidden Valley® Ra...|\n",
      "| Rao's® Frozen Pizza|\n",
      "|Barilla® pasta, s...|\n",
      "|Bio-Oil® products...|\n",
      "|BallPark® buns, b...|\n",
      "|Hidden Valley® Ra...|\n",
      "|Tyson Products, s...|\n",
      "|Back to the Roots...|\n",
      "|Squirrel, The Bed...|\n",
      "|Sara Lee® Delight...|\n",
      "|Glad® ForceFlex M...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|               OFFER|count|\n",
      "+--------------------+-----+\n",
      "| Spend $185 at Shaws|    1|\n",
      "|Back to the Roots...|    1|\n",
      "|SKITTLES®, select...|    1|\n",
      "|Gorton's at selec...|    2|\n",
      "|Spend $50 on a Fu...|    1|\n",
      "|Jack Link's®, sel...|    1|\n",
      "|Ben & Jerry's®, s...|    1|\n",
      "|Wesson® Oil Products|    1|\n",
      "|Spend $115 at Saf...|    1|\n",
      "|Hidden Valley® Ra...|    1|\n",
      "| Rao's® Frozen Pizza|    1|\n",
      "|Barilla® pasta, s...|    1|\n",
      "|Bio-Oil® products...|    1|\n",
      "|BallPark® buns, b...|    1|\n",
      "|Hidden Valley® Ra...|    1|\n",
      "|Tyson Products, s...|    1|\n",
      "|Back to the Roots...|    1|\n",
      "|Squirrel, The Bed...|    1|\n",
      "|Sara Lee® Delight...|    1|\n",
      "|Glad® ForceFlex M...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|            RETAILER|\n",
      "+--------------------+\n",
      "|              SMITHS|\n",
      "| UNITED SUPERMARKETS|\n",
      "|        KING SOOPERS|\n",
      "|               CHEWY|\n",
      "|                VONS|\n",
      "|SPROUTS FARMERS M...|\n",
      "|DICKEYS BARBECUE PIT|\n",
      "|     DILLONS GROCERY|\n",
      "|DOLLAR GENERAL STORE|\n",
      "|         STAR MARKET|\n",
      "|              COSTCO|\n",
      "|                  NA|\n",
      "|          ALBERTSONS|\n",
      "|           PAVILIONS|\n",
      "|                 QFC|\n",
      "|LOWES HOME IMPROV...|\n",
      "|          FRED MEYER|\n",
      "|              KROGER|\n",
      "|         FARMER BOYS|\n",
      "|              RALPHS|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            RETAILER|count|\n",
      "+--------------------+-----+\n",
      "|              SMITHS|    1|\n",
      "| UNITED SUPERMARKETS|    1|\n",
      "|        KING SOOPERS|    1|\n",
      "|               CHEWY|    2|\n",
      "|                VONS|    5|\n",
      "|SPROUTS FARMERS M...|    2|\n",
      "|DICKEYS BARBECUE PIT|    3|\n",
      "|     DILLONS GROCERY|    2|\n",
      "|DOLLAR GENERAL STORE|    2|\n",
      "|         STAR MARKET|    5|\n",
      "|              COSTCO|    2|\n",
      "|                  NA|  147|\n",
      "|          ALBERTSONS|    5|\n",
      "|           PAVILIONS|    5|\n",
      "|                 QFC|    1|\n",
      "|LOWES HOME IMPROV...|    5|\n",
      "|          FRED MEYER|    2|\n",
      "|              KROGER|    1|\n",
      "|         FARMER BOYS|    2|\n",
      "|              RALPHS|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|               BRAND|\n",
      "+--------------------+\n",
      "|        SUPER COFFEE|\n",
      "|                 BAI|\n",
      "|          SIO BEAUTY|\n",
      "|             TALENTI|\n",
      "|               ALEVE|\n",
      "|         SOL CERVEZA|\n",
      "|             FLONASE|\n",
      "|                BAYS|\n",
      "|              PERSIL|\n",
      "|                GLAD|\n",
      "|               CHEWY|\n",
      "|          JACK LINKS|\n",
      "|                VONS|\n",
      "|              EVOLVE|\n",
      "|                M&MS|\n",
      "|               ANDRE|\n",
      "|DICKEYS BARBECUE PIT|\n",
      "|               PUREX|\n",
      "|         STAR MARKET|\n",
      "|              COSTCO|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|               BRAND|count|\n",
      "+--------------------+-----+\n",
      "|        SUPER COFFEE|    2|\n",
      "|                 BAI|    2|\n",
      "|          SIO BEAUTY|    1|\n",
      "|             TALENTI|    1|\n",
      "|               ALEVE|    3|\n",
      "|         SOL CERVEZA|    1|\n",
      "|             FLONASE|    1|\n",
      "|                BAYS|    1|\n",
      "|              PERSIL|    1|\n",
      "|                GLAD|    2|\n",
      "|               CHEWY|    1|\n",
      "|          JACK LINKS|    1|\n",
      "|                VONS|    5|\n",
      "|              EVOLVE|    1|\n",
      "|                M&MS|    2|\n",
      "|               ANDRE|    1|\n",
      "|DICKEYS BARBECUE PIT|    3|\n",
      "|               PUREX|    1|\n",
      "|         STAR MARKET|    5|\n",
      "|              COSTCO|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df2 = spark.read.csv(\"C:/Users/karth/Desktop/Fetch_project/Data/offer_retailer.csv\", header=True, inferSchema=True)\n",
    "\n",
    "data_df2.filter(data_df2[\"OFFER\"].isNull()).show()\n",
    "\n",
    "data_df2.filter(data_df2[\"RETAILER\"].isNull()).show()\n",
    "\n",
    "data_df2.filter(data_df2[\"BRAND\"].isNull()).show()\n",
    "\n",
    "data2 = data_df2.fillna(\"NA\")\n",
    "\n",
    "data2.filter(data2[\"RETAILER\"] == \"NA\").show()\n",
    "\n",
    "data2.describe().show()\n",
    "\n",
    "unique_OFFER = data2.select(\"OFFER\").distinct()\n",
    "unique_OFFER.show()\n",
    "\n",
    "OFFER_count = data2.groupBy(\"OFFER\").count()\n",
    "OFFER_count.show()\n",
    "\n",
    "unique_RETAILER = data2.select(\"RETAILER\").distinct()\n",
    "unique_RETAILER.show()\n",
    "\n",
    "RETAILER_count = data2.groupBy(\"RETAILER\").count()\n",
    "RETAILER_count.show()\n",
    "\n",
    "BRAND_categories = data2.select(\"BRAND\").distinct()\n",
    "BRAND_categories.show()\n",
    "\n",
    "BRAND_counts = data2.groupBy(\"BRAND\").count()\n",
    "BRAND_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------+\n",
      "|             BRAND|BRAND_BELONGS_TO_CATEGORY|\n",
      "+------------------+-------------------------+\n",
      "|  CASEYS GEN STORE|         Tobacco Products|\n",
      "|  CASEYS GEN STORE|                   Mature|\n",
      "|            EQUATE|             Hair Removal|\n",
      "|         PALMOLIVE|              Bath & Body|\n",
      "|              DAWN|              Bath & Body|\n",
      "|          BARBASOL|             Hair Removal|\n",
      "|            KROGER|                   Bakery|\n",
      "|        SKINTIMATE|             Hair Removal|\n",
      "|     DAWN PLATINUM|              Bath & Body|\n",
      "|KIRKLAND SIGNATURE|              Bath & Body|\n",
      "|          RED BULL|     Carbonated Soft D...|\n",
      "|         COCA-COLA|     Carbonated Soft D...|\n",
      "|              AJAX|              Bath & Body|\n",
      "|            EQUATE|              Bath & Body|\n",
      "|         DR PEPPER|     Carbonated Soft D...|\n",
      "|        BODYCOLOGY|          Body Fragrances|\n",
      "|           KINDERS|             Dips & Salsa|\n",
      "|    BODY FANTASIES|          Body Fragrances|\n",
      "|      MOUNTAIN DEW|     Carbonated Soft D...|\n",
      "|           MONSTER|     Carbonated Soft D...|\n",
      "+------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|    PRODUCT_CATEGORY|IS_CHILD_CATEGORY_TO|\n",
      "+--------------------+--------------------+\n",
      "|     Red Pasta Sauce|         Pasta Sauce|\n",
      "|Alfredo & White P...|         Pasta Sauce|\n",
      "|    Cooking & Baking|              Pantry|\n",
      "|    Packaged Seafood|              Pantry|\n",
      "|    Feminine Hygeine|   Health & Wellness|\n",
      "|        Leafy Salads|       Deli & Bakery|\n",
      "|               Cream|               Dairy|\n",
      "|              Coffee|           Beverages|\n",
      "|       Frozen Fruits|              Frozen|\n",
      "|   Nut Butters & Jam|              Pantry|\n",
      "|     Frozen Desserts|              Frozen|\n",
      "|               Decor|       Home & Garden|\n",
      "|               Candy|              Snacks|\n",
      "|Cereal, Granola, ...|              Pantry|\n",
      "|        Frozen Sides|              Frozen|\n",
      "|  Dairy Alternatives|               Dairy|\n",
      "|Meal Replacement ...|           Beverages|\n",
      "|            Pretzels|              Snacks|\n",
      "|         Snack Mixes|              Snacks|\n",
      "|        Frozen Meals|              Frozen|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-------------------+--------------------+\n",
      "|               OFFER|           RETAILER|               BRAND|\n",
      "+--------------------+-------------------+--------------------+\n",
      "|Spend $50 on a Fu...|          SAMS CLUB|           SAMS CLUB|\n",
      "|Beyond Meat® Plan...|                 NA|         BEYOND MEAT|\n",
      "|Good Humor Vienne...|                 NA|          GOOD HUMOR|\n",
      "|Butterball, selec...| DILLONS FOOD STORE|          BUTTERBALL|\n",
      "|GATORADE® Fast Tw...|             AMAZON|            GATORADE|\n",
      "|Emmy's Organics® ...|                 NA|        EMMYS POP UP|\n",
      "|Dr Pepper®, Regul...|UNITED SUPERMARKETS|           DR PEPPER|\n",
      "|Arnold, Brownberr...|            WALMART|ARNOLD BROWNBERRY...|\n",
      "|Barilla® Pesto Sauce|                 NA|             BARILLA|\n",
      "|Any General Mills...|                 NA|                  NA|\n",
      "|Good Rewards Memb...|                 NA|ANNIES HOMEGROWN ...|\n",
      "|Egglife Egg White...|               ALDI|             EGGLIFE|\n",
      "|Spend $20 at Zaxby's|             ZAXBYS|              ZAXBYS|\n",
      "| Spend $10 at Subway|             SUBWAY|              SUBWAY|\n",
      "|DOVE® Chocolate, ...|                 NA|      DOVE CHOCOLATE|\n",
      "|Hellmann's® OR Be...|                 NA|HELLMANNS BEST FOODS|\n",
      "|M&M'S®, select si...|                 NA|                M&MS|\n",
      "|GATORLYTE® OR GAT...|                 NA|            GATORADE|\n",
      "|Beyond Steak™ Pla...|             TARGET|         BEYOND MEAT|\n",
      "|Red Gold Tomato K...|                 NA|            RED GOLD|\n",
      "+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-----------------+-------------------------+------------------+--------------------+--------------------+--------+\n",
      "|summary|            BRAND|BRAND_BELONGS_TO_CATEGORY|  PRODUCT_CATEGORY|IS_CHILD_CATEGORY_TO|               OFFER|RETAILER|\n",
      "+-------+-----------------+-------------------------+------------------+--------------------+--------------------+--------+\n",
      "|  count|            10291|                     9906|               118|                 118|                 385|     385|\n",
      "|   mean|          1000.45|                     null|              null|                null|                null|    null|\n",
      "| stddev|841.6671097792823|                     null|              null|                null|                null|    null|\n",
      "|    min|                1|       Adult Incontinence|Adult Incontinence|             Alcohol|12 Pack OR 2 Lite...|    ACME|\n",
      "|    max|    breath savers|                   Yogurt|            Yogurt|Sports Drinks & E...|Wonderworks™ Keto...|  ZAXBYS|\n",
      "+-------+-----------------+-------------------------+------------------+--------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the datasets into dataframes\n",
    "data.show()\n",
    "data1.show()\n",
    "data2.show()\n",
    "\n",
    "# Combining the dataframes vertically\n",
    "dff = data.unionByName(data1, allowMissingColumns=True).unionByName(data2, allowMissingColumns=True)\n",
    "\n",
    "# Viewing the merged dataframe\n",
    "dff.describe().show()\n",
    "\n",
    "df = dff.fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------+----------------+--------------------+-----+--------+\n",
      "|             BRAND|BRAND_BELONGS_TO_CATEGORY|PRODUCT_CATEGORY|IS_CHILD_CATEGORY_TO|OFFER|RETAILER|\n",
      "+------------------+-------------------------+----------------+--------------------+-----+--------+\n",
      "|  CASEYS GEN STORE|         Tobacco Products|            null|                null| null|    null|\n",
      "|  CASEYS GEN STORE|                   Mature|            null|                null| null|    null|\n",
      "|            EQUATE|             Hair Removal|            null|                null| null|    null|\n",
      "|         PALMOLIVE|              Bath & Body|            null|                null| null|    null|\n",
      "|              DAWN|              Bath & Body|            null|                null| null|    null|\n",
      "|          BARBASOL|             Hair Removal|            null|                null| null|    null|\n",
      "|            KROGER|                   Bakery|            null|                null| null|    null|\n",
      "|        SKINTIMATE|             Hair Removal|            null|                null| null|    null|\n",
      "|     DAWN PLATINUM|              Bath & Body|            null|                null| null|    null|\n",
      "|KIRKLAND SIGNATURE|              Bath & Body|            null|                null| null|    null|\n",
      "|          RED BULL|     Carbonated Soft D...|            null|                null| null|    null|\n",
      "|         COCA-COLA|     Carbonated Soft D...|            null|                null| null|    null|\n",
      "|              AJAX|              Bath & Body|            null|                null| null|    null|\n",
      "|            EQUATE|              Bath & Body|            null|                null| null|    null|\n",
      "|         DR PEPPER|     Carbonated Soft D...|            null|                null| null|    null|\n",
      "|        BODYCOLOGY|          Body Fragrances|            null|                null| null|    null|\n",
      "|           KINDERS|             Dips & Salsa|            null|                null| null|    null|\n",
      "|    BODY FANTASIES|          Body Fragrances|            null|                null| null|    null|\n",
      "|      MOUNTAIN DEW|     Carbonated Soft D...|            null|                null| null|    null|\n",
      "|           MONSTER|     Carbonated Soft D...|            null|                null| null|    null|\n",
      "+------------------+-------------------------+----------------+--------------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame\n",
    "pandas_df = df.toPandas()\n",
    "\n",
    "# Write Pandas DataFrame to save as CSV file\n",
    "pandas_df.to_csv('file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until Here I performed the data scarping and anlysis, unified the different datasets and merged them as one after this Performed the data unifying by mapping them.\n",
    " \n",
    "**Text Data Preprocessing using PySpark**\n",
    "\n",
    "Now, I focus on preparing the text data within the unified dataset. Our goal is to clean and preprocess the text features using PySpark.\n",
    "\n",
    "**Data Deduplication**\n",
    "Duplicate rows in the dataset are removed to ensure data integrity.\n",
    "\n",
    "**Text Cleaning**\n",
    "Text data is cleaned by converting it to lowercase and removing special characters.\n",
    "\n",
    "**Text Tokenization**\n",
    "The text is tokenized, breaking it into individual words, and stored in a new \"words\" column.\n",
    "\n",
    "**Stop Word Removal**\n",
    "Common stop words are removed from the tokenized words.\n",
    "\n",
    "**Lemmatization with Word2Vec (Example)**\n",
    "Word2Vec is used for lemmatization, converting text to numerical vectors. If useful in the future.\n",
    "\n",
    "\n",
    "This preprocessing prepares the text data for analysis and machine learning tasks.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\karth\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: torch in c:\\users\\karth\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\karth\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\karth\\anaconda3\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\karth\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\karth\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.63.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.19.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: nltk in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.4.5)\n",
      "Requirement already satisfied: torchvision in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.30.2)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\karth\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\karth\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\karth\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (7.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\karth\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (2.22.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\karth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\karth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\karth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from requests->torchvision->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from requests->torchvision->sentence-transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from requests->torchvision->sentence-transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->huggingface-hub>=0.4.0->sentence-transformers) (2.2.0)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "Successfully installed urllib3-1.25.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: conda 4.13.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n",
      "ERROR: selenium 4.3.0 has requirement urllib3[secure,socks]~=1.26, but you'll have urllib3 1.25.11 which is incompatible.\n",
      "ERROR: elastic-transport 8.4.1 has requirement urllib3<2,>=1.26.2, but you'll have urllib3 1.25.11 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in c:\\users\\karth\\anaconda3\\lib\\site-packages (8.10.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from elasticsearch) (8.4.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\karth\\anaconda3\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch) (2022.5.18.1)\n",
      "Collecting urllib3<2,>=1.26.2\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "Successfully installed urllib3-1.26.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: conda 4.13.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n",
      "ERROR: requests 2.22.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.18 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\karth\\anaconda3\\lib\\site-packages (4.63.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\karth\\anaconda3\\lib\\site-packages (from tqdm) (0.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\n",
      "ERROR: No matching distribution found for faiss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\karth\\anaconda3\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: sklearn in c:\\users\\karth\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\karth\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\karth\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install torch\n",
    "!pip install pandas\n",
    "!pip install numpy \n",
    "!pip install sentence-transformers \n",
    "!pip install elasticsearch\n",
    "!pip install tqdm\n",
    "!pip install faiss-cpu\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+----------------------+------------------------------------------+----------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+------------------------------------------------------------------+\n",
      "|OFFER                                                                          |RETAILER_mapped       |BRAND                                     |PRODUCT_CATEGORY|words                                                                                      |filtered_words                                                                 |features                                                          |\n",
      "+-------------------------------------------------------------------------------+----------------------+------------------------------------------+----------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+------------------------------------------------------------------+\n",
      "|sign up for mcalisters deli rewards tap for details                            |mcalisters deli       |milk                                      |null            |[sign, up, for, mcalisters, deli, rewards, tap, for, details]                              |[sign, mcalisters, deli, rewards, tap, details]                                |[0.7404392759005228,-1.2139235138893127,0.2996042420466741]       |\n",
      "|welchs juicefuls juicy fruit snacks 14 count at target                         |target                |fruit  vegetable snacks                   |null            |[welchs, juicefuls, juicy, fruit, snacks, 14, count, at, target]                           |[welchs, juicefuls, juicy, fruit, snacks, 14, count, target]                   |[-0.08308646129444242,0.10003459302242845,0.014074360951781273]   |\n",
      "|colgate toothpaste and colgate toothbrush select varieties at walmart or target|target                |oral care                                 |toothpaste      |[colgate, toothpaste, and, colgate, toothbrush, select, varieties, at, walmart, or, target]|[colgate, toothpaste, colgate, toothbrush, select, varieties, walmart, target] |[-0.2841463265940547,-0.023545523639768362,-0.16324050771072507]  |\n",
      "|12 pack or 2 liter and whole pizza at caseys                                   |caseys general store  |cooking  baking                           |null            |[12, pack, or, 2, liter, and, whole, pizza, at, caseys]                                    |[12, pack, 2, liter, whole, pizza, caseys]                                     |[-0.25455281351293835,0.2195732556283474,-0.20234722005469458]    |\n",
      "|general mills products select brands spend 35                                  |null                  |frozen breakfast                          |null            |[general, mills, products, select, brands, spend, 35]                                      |[general, mills, products, select, brands, spend, 35]                          |[-0.5923023628337042,0.053837993315288,-0.03370652161538601]      |\n",
      "|fresh step outstretch cat litter                                               |null                  |makeup                                    |null            |[fresh, step, outstretch, cat, litter]                                                     |[fresh, step, outstretch, cat, litter]                                         |[-0.1727990295737982,0.08934138417243959,-0.05657616704702378]    |\n",
      "|sara lee bread select varieties buy 2                                          |walmart               |bread                                     |null            |[sara, lee, bread, select, varieties, buy, 2]                                              |[sara, lee, bread, select, varieties, buy, 2]                                  |[-0.5765627082437277,-0.1907835134438106,-0.3891312118087496]     |\n",
      "|goya adobo seasoning 8 ounce                                                   |null                  |water                                     |null            |[goya, adobo, seasoning, 8, ounce]                                                         |[goya, adobo, seasoning, 8, ounce]                                             |[0.09616366550326348,0.06652967482805253,-0.5419261455535889]     |\n",
      "|when you join costco as a gold star member new members only                    |costco                |null                                      |null            |[when, you, join, costco, as, a, gold, star, member, new, members, only]                   |[join, costco, gold, star, member, new, members]                               |[-0.024708737885313373,0.0023081534143005096,0.042191301073346815]|\n",
      "|ratio keto friendly cereal or granola                                          |null                  |cereal granola  toaster pastries          |null            |[ratio, keto, friendly, cereal, or, granola]                                               |[ratio, keto, friendly, cereal, granola]                                       |[-0.023038372024893762,0.06769592575728893,-0.002865526080131531] |\n",
      "|hellmanns  best foods vegan dressing or spread                                 |null                  |dressings                                 |null            |[hellmanns, , best, foods, vegan, dressing, or, spread]                                    |[hellmanns, , best, foods, vegan, dressing, spread]                            |[-0.13812628228749546,0.15322711425168173,-0.007603957184723445]  |\n",
      "|shop 2 times at safeway                                                        |safeway               |candy                                     |gum             |[shop, 2, times, at, safeway]                                                              |[shop, 2, times, safeway]                                                      |[-0.27152480371296406,0.019282075809314847,-0.15196522325277328]  |\n",
      "|perfect keto collagen peptides online at amazon                                |amazon                |medicines  treatments                     |null            |[perfect, keto, collagen, peptides, online, at, amazon]                                    |[perfect, keto, collagen, peptides, online, amazon]                            |[0.06019240369399388,0.05747562755520145,0.15744274233778316]     |\n",
      "|coors light miller lite or vizzy 12 packs buy 2                                |null                  |hard seltzers sodas waters lemonades  teas|null            |[coors, light, miller, lite, or, vizzy, 12, packs, buy, 2]                                 |[coors, light, miller, lite, vizzy, 12, packs, buy, 2]                         |[-0.38274387187427944,0.16326440850065813,-0.32425596482223934]   |\n",
      "|evolve plantbased protein shake 4 count select varieties at whole foods        |whole foods market    |meal replacement beverages                |null            |[evolve, plantbased, protein, shake, 4, count, select, varieties, at, whole, foods]        |[evolve, plantbased, protein, shake, 4, count, select, varieties, whole, foods]|[-0.35741077773272995,0.04211440677754581,-0.08669325299561025]   |\n",
      "|goya adobo seasoning 8 ounce                                                   |null                  |crackers                                  |null            |[goya, adobo, seasoning, 8, ounce]                                                         |[goya, adobo, seasoning, 8, ounce]                                             |[0.09616366550326348,0.06652967482805253,-0.5419261455535889]     |\n",
      "|sara lee or alfaros artesano bread buy 2                                       |null                  |bread                                     |null            |[sara, lee, or, alfaros, artesano, bread, buy, 2]                                          |[sara, lee, alfaros, artesano, bread, buy, 2]                                  |[-0.3183495426284415,-0.14621273321764808,-0.35276980698108673]   |\n",
      "|back to the roots soils select varieties at walmart or lowes                   |lowes home improvement|packaged meals  sides                     |null            |[back, to, the, roots, soils, select, varieties, at, walmart, or, lowes]                   |[back, roots, soils, select, varieties, walmart, lowes]                        |[-0.25071928064737997,-0.07008434512785502,-0.08770170115998813]  |\n",
      "|cesar wet dog food spend 20                                                    |null                  |cooking  baking                           |null            |[cesar, wet, dog, food, spend, 20]                                                         |[cesar, wet, dog, food, spend, 20]                                             |[-0.003378458321094513,0.10405960368613401,0.23291343140105406]   |\n",
      "|extra select varieties                                                         |null                  |gum                                       |null            |[extra, select, varieties]                                                                 |[extra, select, varieties]                                                     |[-0.5804481928547223,-0.20479777952035266,-0.22124143689870834]   |\n",
      "+-------------------------------------------------------------------------------+----------------------+------------------------------------------+----------------+-------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'unified_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4fd237fd144a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Write Pandas DataFrame to CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mpandas_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unified_test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# Stop the Spark session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3480\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3481\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3482\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3483\u001b[0m         )\n\u001b[0;32m   3484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         ) as handles:\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'unified_test.csv'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lower, regexp_replace, col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "# Initializing a Spark session\n",
    "spark = SparkSession.builder.appName(\"TextProcessing\").getOrCreate()\n",
    "\n",
    "#loading dataset\n",
    "unified_df = spark.read.option(\"header\", \"true\").csv(\"C:/Users/karth/Desktop/Fetch_project/unified.csv\")\n",
    "\n",
    "# Removed complete duplicate rows\n",
    "unified_df = unified_df.dropDuplicates()\n",
    "\n",
    "for col_name in unified_df.columns:\n",
    "    if unified_df.schema[col_name].dataType.typeName() == 'string':\n",
    "        unified_df = unified_df.withColumn(col_name, lower(col(col_name)))\n",
    "        unified_df = unified_df.withColumn(col_name, regexp_replace(col(col_name), \"[^a-zA-Z0-9\\\\s]\", \"\"))\n",
    "\n",
    "\n",
    "# Tokenizing the text\n",
    "tokenizer = Tokenizer(inputCol=\"OFFER\", outputCol=\"words\")\n",
    "text_df = tokenizer.transform(unified_df)\n",
    "\n",
    "# Removed stop words and Lemmatization using Word2Vec\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "text_df = remover.transform(text_df)\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered_words\", outputCol=\"features\")\n",
    "model = word2Vec.fit(text_df)\n",
    "text_df = model.transform(text_df)\n",
    "\n",
    "# Dispalying the processed DataFrame\n",
    "text_df.show(truncate=False)\n",
    "\n",
    "#Convert PySpark DataFrame to Pandas DataFrame and to save as CSV file\n",
    "import pandas as pd\n",
    "pandas_df = text_df.toPandas()\n",
    "pandas_df.to_csv('unified_test.csv', index=False)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I used Hugging Face's Sentence Transformers to find semantic matches in a dataset. It encodes offers into embeddings and performs K-nearest neighbors search. An example query, \"TARGET,\" is used to find and display the top 10 similar offers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 - Distance: 43.3433\n",
      "Offer: arber at target\n",
      "\n",
      "Result 2 - Distance: 63.1514\n",
      "Offer: loral paris true match foundation at target\n",
      "\n",
      "Result 3 - Distance: 63.4933\n",
      "Offer: loreal paris true match foundation at target\n",
      "\n",
      "Result 4 - Distance: 68.3754\n",
      "Offer: beyond steak plantbased seared tips 10 ounce buy 2 at target\n",
      "\n",
      "Result 5 - Distance: 68.3754\n",
      "Offer: beyond steak plantbased seared tips 10 ounce buy 2 at target\n",
      "\n",
      "Result 6 - Distance: 68.3754\n",
      "Offer: beyond steak plantbased seared tips 10 ounce buy 2 at target\n",
      "\n",
      "Result 7 - Distance: 74.9721\n",
      "Offer: beyond steak plantbased seared tips 10 ounce at target\n",
      "\n",
      "Result 8 - Distance: 74.9721\n",
      "Offer: beyond steak plantbased seared tips 10 ounce at target\n",
      "\n",
      "Result 9 - Distance: 74.9721\n",
      "Offer: beyond steak plantbased seared tips 10 ounce at target\n",
      "\n",
      "Result 10 - Distance: 75.2401\n",
      "Offer: back to the roots grow seed starting pots or germination trays at walmart or target\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import faiss\n",
    "\n",
    "# Initializing a SentenceTransformer model on Hugging Face\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "df = pd.read_csv('C:/Users/karth/Desktop/Fetch_project/unified_test.csv')\n",
    "\n",
    "offer_embeddings = model.encode(df['OFFER'].tolist())\n",
    "\n",
    "# Builded an index for KNN search\n",
    "index = faiss.IndexFlatL2(offer_embeddings.shape[1])\n",
    "index.add(offer_embeddings)\n",
    "\n",
    "# Function to perform K-nearest neighbors (KNN) search\n",
    "def knn_search(input_query, index, k=10):\n",
    "    query_embedding = model.encode([input_query])\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    search_results = []\n",
    "    for i in range(k):\n",
    "        search_results.append((indices[0][i], distances[0][i]))\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "# Input query\n",
    "input_query = \"TARGET\"\n",
    "\n",
    "# Perform KNN semantic search and get top 10 results\n",
    "top_results = knn_search(input_query, index, k=10)\n",
    "\n",
    "# Print the list of offers with distance scores\n",
    "for i, (index, distance) in enumerate(top_results):\n",
    "    print(f\"Result {i + 1} - Distance: {distance:.4f}\")\n",
    "    print(f\"Offer: {df.iloc[index]['OFFER']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now after observing the above models performance I used Hugging Face's Sentence Transformers to encode offers into embeddings and perform K-nearest neighbors (KNN) search. Here we employed scikit-learn's NearestNeighbors to find the top 20 similar offers to the example query \"cheese\" based on cosine distance. The results are displayed with their distances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 - Distance: 0.3363\n",
      "Offer: arber at target\n",
      "\n",
      "Result 2 - Distance: 0.5424\n",
      "Offer: loreal paris true match foundation at target\n",
      "\n",
      "Result 3 - Distance: 0.5498\n",
      "Offer: loral paris true match foundation at target\n",
      "\n",
      "Result 4 - Distance: 0.5825\n",
      "Offer: beyond steak plantbased seared tips 10 ounce buy 2 at target\n",
      "\n",
      "Result 5 - Distance: 0.5825\n",
      "Offer: beyond steak plantbased seared tips 10 ounce buy 2 at target\n",
      "\n",
      "Result 6 - Distance: 0.5825\n",
      "Offer: beyond steak plantbased seared tips 10 ounce buy 2 at target\n",
      "\n",
      "Result 7 - Distance: 0.6139\n",
      "Offer: talenti mini bars\n",
      "\n",
      "Result 8 - Distance: 0.6139\n",
      "Offer: talenti mini bars\n",
      "\n",
      "Result 9 - Distance: 0.6204\n",
      "Offer: beyond steak plantbased seared tips 10 ounce at target\n",
      "\n",
      "Result 10 - Distance: 0.6204\n",
      "Offer: beyond steak plantbased seared tips 10 ounce at target\n",
      "\n",
      "Result 11 - Distance: 0.6204\n",
      "Offer: beyond steak plantbased seared tips 10 ounce at target\n",
      "\n",
      "Result 12 - Distance: 0.6276\n",
      "Offer: loral paris makeup spend 30 at target\n",
      "\n",
      "Result 13 - Distance: 0.6509\n",
      "Offer: loral paris makeup spend 35 at target\n",
      "\n",
      "Result 14 - Distance: 0.6660\n",
      "Offer: loral paris hair color select varieties spend 25 at target\n",
      "\n",
      "Result 15 - Distance: 0.6733\n",
      "Offer: loral paris hair color select varieties spend 19 at target\n",
      "\n",
      "Result 16 - Distance: 0.6755\n",
      "Offer: dove hand wash select varieties buy 2 at target\n",
      "\n",
      "Result 17 - Distance: 0.6755\n",
      "Offer: dove hand wash select varieties buy 2 at target\n",
      "\n",
      "Result 18 - Distance: 0.6755\n",
      "Offer: dove hand wash select varieties buy 2 at target\n",
      "\n",
      "Result 19 - Distance: 0.6755\n",
      "Offer: dove hand wash select varieties buy 2 at target\n",
      "\n",
      "Result 20 - Distance: 0.6773\n",
      "Offer: dove hand wash select varieties at target\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "df = pd.read_csv('C:/Users/karth/Desktop/Fetch_project/unified_test.csv')\n",
    "\n",
    "offer_embeddings = model.encode(df['OFFER'].tolist())\n",
    "\n",
    "# Building an index for KNN search using scikit-learn's NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=10, metric='cosine', n_jobs=-1)\n",
    "nn.fit(offer_embeddings)\n",
    "\n",
    "# Function to perform K-nearest neighbors (KNN) search\n",
    "def knn_search(input_query, nn, k=10):\n",
    "    query_embedding = model.encode([input_query])\n",
    "    distances, indices = nn.kneighbors(query_embedding, n_neighbors=k)\n",
    "    \n",
    "    # Converted the results to a list format\n",
    "    search_results = []\n",
    "    for i in range(k):\n",
    "        result = {\n",
    "            \"index\": indices[0][i],\n",
    "            \"distance\": distances[0][i],\n",
    "            \"offer\": df.iloc[indices[0][i]]['OFFER']\n",
    "        }\n",
    "        search_results.append(result)\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "input_query = \"Target\"\n",
    "\n",
    "top_results = knn_search(input_query, nn, k=20)\n",
    "\n",
    "for i, result in enumerate(top_results):\n",
    "    print(f\"Result {i + 1} - Distance: {result['distance']:.4f}\")\n",
    "    print(f\"Offer: {result['offer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Both above and below codes use Sentence Transformers to encode offers and find similar offers based on cosine distance. However, the below code introduces an intelligent search function that identifies the type of input text (e.g., retailer, brand, or product category) and performs tailored searches, providing more context-specific results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offer: tyson products select varieties spend 20 at sams club\n",
      "Retailer: sams club\n",
      "Brand: frozen beef\n",
      "Product Category: nan\n",
      "Distance Score: 0.5882034\n",
      "\n",
      "Offer: tyson products select varieties spend 20 at sams club\n",
      "Retailer: sams club\n",
      "Brand: packaged meat\n",
      "Product Category: nan\n",
      "Distance Score: 0.5882034\n",
      "\n",
      "Offer: spend 50 on a fullpriced new club membership\n",
      "Retailer: sams club\n",
      "Brand: nan\n",
      "Product Category: nan\n",
      "Distance Score: 0.60120666\n",
      "\n",
      "Offer: georges farmers market chicken wings at sams club\n",
      "Retailer: sams club\n",
      "Brand: nan\n",
      "Product Category: nan\n",
      "Distance Score: 0.6272481\n",
      "\n",
      "Offer: spend 110 on a fullpriced new plus membership and receive an additional 10000 points\n",
      "Retailer: sams club\n",
      "Brand: nan\n",
      "Product Category: nan\n",
      "Distance Score: 0.7857358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Loaded the paraphrse model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "df = pd.read_csv('C:/Users/karth/Desktop/Fetch_project/unified_test.csv')\n",
    "\n",
    "offer_embeddings = model.encode(df['OFFER'].tolist())\n",
    "\n",
    "# Define k asuming that the datest can provide atleast 10 offers with the given query\n",
    "k = 10 \n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=k, metric='cosine', n_jobs=-1)\n",
    "nn.fit(offer_embeddings)\n",
    "\n",
    "# Function to perform K-nearest neighbors (KNN) search\n",
    "def knn_search(input_query, nn, k):\n",
    "    query_embedding = model.encode([input_query])\n",
    "    \n",
    "    # Perform a KNN search\n",
    "    distances, indices = nn.kneighbors(query_embedding, n_neighbors=k)\n",
    "    \n",
    "    # Converted the results to a list format\n",
    "    search_results = []\n",
    "    for i in range(k):\n",
    "        result = {\n",
    "            \"index\": indices[0][i],\n",
    "            \"distance\": distances[0][i],\n",
    "            \"offer\": df.iloc[indices[0][i]]['OFFER'],\n",
    "            \"retailer\": df.iloc[indices[0][i]]['RETAILER_mapped'],\n",
    "            \"brand\": df.iloc[indices[0][i]]['BRAND'],\n",
    "            \"product_category\": df.iloc[indices[0][i]]['PRODUCT_CATEGORY'],\n",
    "        }\n",
    "        search_results.append(result)\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "def search(input_text, nn, k):\n",
    "    # To Determine the type of search based on input_text\n",
    "    search_type = \"offer\"\n",
    "    if input_text in df['PRODUCT_CATEGORY'].values:\n",
    "        search_type = \"PRODUCT_CATEGORY\"\n",
    "    elif input_text in df['BRAND'].values:\n",
    "        search_type = \"BRAND\"\n",
    "    elif input_text in df['RETAILER_mapped'].values:\n",
    "        search_type = \"RETAILER_mapped\"\n",
    "    \n",
    "    if search_type == \"offer\":\n",
    "        # Perform KNN semantic search for offers\n",
    "        results = knn_search(input_text, nn, k)\n",
    "    else:\n",
    "        # Filter the dataset based on the search type\n",
    "        filtered_df = df[df[search_type] == input_text]\n",
    "        if not filtered_df.empty:\n",
    "            # Encode the filtered offers and perform KNN search\n",
    "            query_embedding = model.encode([input_text])\n",
    "            filtered_offer_embeddings = model.encode(filtered_df['OFFER'].tolist())\n",
    "            # Define k based on the number of samples in the filtered dataset\n",
    "            k = min(k, len(filtered_offer_embeddings))\n",
    "            filtered_nn = NearestNeighbors(n_neighbors=k, metric='cosine', n_jobs=-1)\n",
    "            filtered_nn.fit(filtered_offer_embeddings)\n",
    "            distances, indices = filtered_nn.kneighbors(query_embedding, n_neighbors=k)\n",
    "            results = []\n",
    "            for i in range(k):\n",
    "                result = {\n",
    "                    \"index\": indices[0][i],\n",
    "                    \"distance\": distances[0][i],\n",
    "                    \"offer\": filtered_df.iloc[indices[0][i]]['OFFER'],\n",
    "                    \"retailer\": filtered_df.iloc[indices[0][i]]['RETAILER_mapped'],\n",
    "                    \"brand\": filtered_df.iloc[indices[0][i]]['BRAND'],\n",
    "                    \"product_category\": filtered_df.iloc[indices[0][i]]['PRODUCT_CATEGORY'],\n",
    "                }\n",
    "                results.append(result)\n",
    "        else:\n",
    "            results = []\n",
    "\n",
    "    return results\n",
    "\n",
    "# input query\n",
    "input_query = \"sams club\"\n",
    "\n",
    "# Now results will only show based on the samples I provided\n",
    "search_results = search(input_query, nn, k)\n",
    "\n",
    "# Printed the list of offers with distance scores\n",
    "for result in search_results:\n",
    "    print(\"Offer:\", result[\"offer\"])\n",
    "    print(\"Retailer:\", result[\"retailer\"])\n",
    "    print(\"Brand:\", result[\"brand\"])\n",
    "    print(\"Product Category:\", result[\"product_category\"])\n",
    "    print(\"Distance Score:\", result[\"distance\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CONCLUSION***\n",
    "\n",
    "**In summary**, the analysis begins with data scraping and initial observations, proceeds to data preprocessing, includes text data preprocessing, and finally demonstrates semantic search capabilities using Sentence Transformers. The Last semantic search code is more advanced, providing **context-specific results** based on the type of input text. Overall, this comprehensive data analysis and search capability enhance data understanding and utilization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
